{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a681d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d06cf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 93.06243133544922 GB\n",
      "Number of CPUs: 64\n",
      "PyTorch is using 64 threads.\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import torch\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "print('Total memory:', psutil.virtual_memory().total / (1024 ** 3), \"GB\")\n",
    "print(\"Number of CPUs:\", multiprocessing.cpu_count())\n",
    "torch.set_num_threads(multiprocessing.cpu_count())\n",
    "\n",
    "print(\"PyTorch is using\", torch.get_num_threads(), \"threads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600da67",
   "metadata": {},
   "source": [
    "# Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb35692",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('filtered_data.csv')\n",
    "sequences = list(data['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a1582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(seq) for seq in sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282d60b",
   "metadata": {},
   "source": [
    "# Regulon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1dc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('promoter_processed.csv')\n",
    "sequences = list(data['Sequences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5735748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(len(seq) for seq in sequences)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9361187",
   "metadata": {},
   "source": [
    "## Embedding Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4f7505-5b72-4697-85c8-dc1cfd2105b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556db82b2c284613afa8d0a65a2ecf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ecc4ebada04b59b40598baa59aa2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31de5a7402314770982959cf6738c56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b890403dcb894bd2b869a5b76a7df068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae35920cea074da3902a6cb895fbf97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gonna start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|██████████| 104/104 [01:18<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Embeddings shape for InstaDeepAI/nucleotide-transformer-500m-1000g: torch.Size([6646, 1280])\n"
     ]
    }
   ],
   "source": [
    "#if you're running on a GPU:\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "def generate_embeddings(model_name):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    sequences_short = sequences  \n",
    "    batch_size = 64 \n",
    "    batches = [sequences_short[i:i + batch_size] for i in range(0, len(sequences_short), batch_size)]\n",
    "\n",
    "    all_embeddings = []\n",
    "    print(\"gonna start\")\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch in tqdm(batches, desc=\"Processing sequences\"):\n",
    "            tokens_ids = tokenizer.batch_encode_plus(batch, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length)[\"input_ids\"]\n",
    "            attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "\n",
    "            #move tensors to GPU\n",
    "            tokens_ids = tokens_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            #model forward pass\n",
    "            torch_outs = model(\n",
    "                tokens_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                encoder_attention_mask=attention_mask,\n",
    "                output_hidden_states=True\n",
    "            )\n",
    "\n",
    "            embeddings = torch_outs['hidden_states'][-1]\n",
    "            attention_mask = torch.unsqueeze(attention_mask, dim=-1)\n",
    "            masked_embeddings = attention_mask * embeddings\n",
    "            \n",
    "            max_sequence_embeddings, _ = torch.max(masked_embeddings, dim=-2)\n",
    "\n",
    "            all_embeddings.append(max_sequence_embeddings)\n",
    "\n",
    "    #move the final result to CPU and convert to NumPy array\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0).cpu()\n",
    "\n",
    "    print(f\"All Embeddings shape for {model_name}: {all_embeddings.shape}\")\n",
    "    \n",
    "    return all_embeddings\n",
    "    \n",
    "all_embeddings_500m = generate_embeddings(\"InstaDeepAI/nucleotide-transformer-500m-1000g\")\n",
    "# all_embeddings_dnab = generate_embeddings(\"zhihan1996/DNABERT-2-117M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ecec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gonna start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:  63%|██████▎   | 66/104 [00:50<00:30,  1.26it/s]"
     ]
    }
   ],
   "source": [
    "all_embeddings_500m_max = generate_embeddings(\"InstaDeepAI/nucleotide-transformer-500m-1000g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee51751-f1f1-484b-8b0b-c74a1bb34a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34027648"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving to a npy file:\n",
    "import pickle\n",
    "\n",
    "np.save('all_embeddings_100m_max', all_embeddings_500m_max)\n",
    "\n",
    "\n",
    "# with open('embeddings_500m_human.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_embeddings, f)\n",
    "\n",
    "pickle_file_size = os.path.getsize('all_embeddings_100m_max.npy')\n",
    "\n",
    "pickle_file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPU Implementation\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\", trust_remote_code=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\", trust_remote_code=True)\n",
    "\n",
    "sequences_short = sequences\n",
    "batch_size = 48 \n",
    "batches = [sequences_short[i:i + batch_size] for i in range(0, len(sequences_short), batch_size)]\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in tqdm(batches, desc=\"Processing sequences\"):\n",
    "    tokens_ids = tokenizer.batch_encode_plus(batch, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length)[\"input_ids\"]\n",
    "    attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "\n",
    "    torch_outs = model(\n",
    "        tokens_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        encoder_attention_mask=attention_mask,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "\n",
    "    embeddings = torch_outs['hidden_states'][-1].detach().numpy()\n",
    "    attention_mask = torch.unsqueeze(attention_mask, dim=-1)\n",
    "    mean_sequence_embeddings = torch.sum(attention_mask * embeddings, axis=-2) / torch.sum(attention_mask, axis=1)\n",
    "\n",
    "    all_embeddings.append(mean_sequence_embeddings)\n",
    "\n",
    "all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "print(f\"All Embeddings shape: {all_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99554c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc83b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
