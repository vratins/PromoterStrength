{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('promoter_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('all_embeddings_100m_max.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6646, 1280)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6646, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequences</th>\n",
       "      <th>Strengths</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1270</th>\n",
       "      <th>feature_1271</th>\n",
       "      <th>feature_1272</th>\n",
       "      <th>feature_1273</th>\n",
       "      <th>feature_1274</th>\n",
       "      <th>feature_1275</th>\n",
       "      <th>feature_1276</th>\n",
       "      <th>feature_1277</th>\n",
       "      <th>feature_1278</th>\n",
       "      <th>feature_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaagaaaataattaattttacagctgttaaaccaaacggttataac...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6646 rows Ã— 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequences  Strengths  feature_0  \\\n",
       "0     tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...          1  -0.936847   \n",
       "1     aaagaaaataattaattttacagctgttaaaccaaacggttataac...          1  -0.946999   \n",
       "2     ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...          1  -0.946999   \n",
       "3     gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...          1  -0.936847   \n",
       "4     aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...          1  -0.939334   \n",
       "...                                                 ...        ...        ...   \n",
       "6641  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6642  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6643  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6644  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6645  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "\n",
       "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "1     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "2     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "3     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "4     -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6641  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6642  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6643  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6644  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6645  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "\n",
       "      feature_7  ...  feature_1270  feature_1271  feature_1272  feature_1273  \\\n",
       "0     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "1     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "2     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "3     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "4     -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "...         ...  ...           ...           ...           ...           ...   \n",
       "6641  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6642  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6643  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6644  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6645  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "\n",
       "      feature_1274  feature_1275  feature_1276  feature_1277  feature_1278  \\\n",
       "0        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "1        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "2        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "3        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "4        -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6641     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6642     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6643     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6644     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6645     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "\n",
       "      feature_1279  \n",
       "0        -0.153779  \n",
       "1        -0.101237  \n",
       "2        -0.101237  \n",
       "3        -0.153779  \n",
       "4        -0.107114  \n",
       "...            ...  \n",
       "6641     -0.107114  \n",
       "6642     -0.107114  \n",
       "6643     -0.107114  \n",
       "6644     -0.107114  \n",
       "6645     -0.107114  \n",
       "\n",
       "[6646 rows x 1282 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = embeddings.shape[1]\n",
    "embeddings_df = pd.DataFrame(data=embeddings, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "combined_df = pd.concat([y, embeddings_df], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5316\n",
      "Test set size: 1330\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a Pandas DataFrame called 'df' with your data\n",
    "# Replace 'your_target_column' with the actual column name you are trying to predict\n",
    "target_column = 'log2_foldchange'\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_shuffled = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Calculate the split indices\n",
    "train_idx, test_idx = train_test_split(df_shuffled.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the train, validation, and test DataFrames\n",
    "df_train = df_shuffled.loc[train_idx]\n",
    "df_test = df_shuffled.loc[test_idx]\n",
    "\n",
    "# Optional: If you want to drop the index columns (reset_index adds a new index column)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the sizes of the resulting DataFrames\n",
    "print(f\"Train set size: {len(df_train)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to CSV files\n",
    "df_train.to_csv('train_data_clf_max.csv', index=False)\n",
    "\n",
    "df_test.to_csv('test_data_clf_max.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, now train a classifier model on the train_data df_train\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(-1, 2)\n",
    "X = df_train.drop(columns=['Sequences','Strengths'], axis=1)\n",
    "y = df_train['Strengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.35      0.43       265\n",
      "           1       0.57      0.24      0.34       228\n",
      "           2       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.68      1064\n",
      "   macro avg       0.62      0.53      0.53      1064\n",
      "weighted avg       0.64      0.68      0.63      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try binary classification for promoter vs. nonpromoter\n",
    "\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(1, 0)\n",
    "\n",
    "# Step 2: Convert all 2 to 1\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(2, 1)\n",
    "\n",
    "X = df_train.drop(columns=['Sequences','Strengths'], axis=1)\n",
    "y = df_train['Strengths']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train another model on weak vs. strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune and improve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
