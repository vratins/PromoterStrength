{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the Best Classification Method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retreiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Shape:  (6646, 2)\n",
      "Embeddings Shape:  (6646, 1280)\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('classification_fasta_processed.csv')\n",
    "embeddings = np.load('all_embeddings_100m_mean.npy')\n",
    "print(\"Y Shape: \", y.shape)\n",
    "print(\"Embeddings Shape: \", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequences</th>\n",
       "      <th>Strengths</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1270</th>\n",
       "      <th>feature_1271</th>\n",
       "      <th>feature_1272</th>\n",
       "      <th>feature_1273</th>\n",
       "      <th>feature_1274</th>\n",
       "      <th>feature_1275</th>\n",
       "      <th>feature_1276</th>\n",
       "      <th>feature_1277</th>\n",
       "      <th>feature_1278</th>\n",
       "      <th>feature_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaagaaaataattaattttacagctgttaaaccaaacggttataac...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6646 rows × 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequences  Strengths  feature_0  \\\n",
       "0     tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...          1  -0.936847   \n",
       "1     aaagaaaataattaattttacagctgttaaaccaaacggttataac...          1  -0.946999   \n",
       "2     ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...          1  -0.946999   \n",
       "3     gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...          1  -0.936847   \n",
       "4     aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...          1  -0.939334   \n",
       "...                                                 ...        ...        ...   \n",
       "6641  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6642  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6643  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6644  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6645  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "\n",
       "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "1     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "2     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "3     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "4     -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6641  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6642  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6643  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6644  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6645  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "\n",
       "      feature_7  ...  feature_1270  feature_1271  feature_1272  feature_1273  \\\n",
       "0     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "1     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "2     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "3     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "4     -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "...         ...  ...           ...           ...           ...           ...   \n",
       "6641  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6642  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6643  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6644  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6645  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "\n",
       "      feature_1274  feature_1275  feature_1276  feature_1277  feature_1278  \\\n",
       "0        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "1        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "2        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "3        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "4        -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6641     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6642     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6643     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6644     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6645     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "\n",
       "      feature_1279  \n",
       "0        -0.153779  \n",
       "1        -0.101237  \n",
       "2        -0.101237  \n",
       "3        -0.153779  \n",
       "4        -0.107114  \n",
       "...            ...  \n",
       "6641     -0.107114  \n",
       "6642     -0.107114  \n",
       "6643     -0.107114  \n",
       "6644     -0.107114  \n",
       "6645     -0.107114  \n",
       "\n",
       "[6646 rows x 1282 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = embeddings.shape[1]\n",
    "embeddings_df = pd.DataFrame(data=embeddings, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "combined_df = pd.concat([y, embeddings_df], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5316\n",
      "Test set size: 1330\n"
     ]
    }
   ],
   "source": [
    "target_column = 'log2_foldchange'\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_shuffled = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Calculate the split indices\n",
    "train_idx, test_idx = train_test_split(df_shuffled.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the train, validation, and test DataFrames\n",
    "df_train = df_shuffled.loc[train_idx]\n",
    "df_test = df_shuffled.loc[test_idx]\n",
    "\n",
    "# Drop the index columns\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the sizes of the resulting DataFrames\n",
    "print(f\"Train set size: {len(df_train)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to CSV files\n",
    "df_train.to_csv('train_data_clf_mean.csv', index=False)\n",
    "df_test.to_csv('test_data_clf_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiClass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier model on the df_train\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(-1, 2)\n",
    "X = df_train.drop(columns=['Sequences','Strengths'], axis=1)\n",
    "y = df_train['Strengths']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: XGB Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Statistics:\n",
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.35      0.43       265\n",
      "           1       0.57      0.24      0.34       228\n",
      "           2       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.68      1064\n",
      "   macro avg       0.62      0.53      0.53      1064\n",
      "weighted avg       0.64      0.68      0.63      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"XGB Classifier Statistics:\")\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'objective': ['multi:softmax'],\n",
    "    'num_class': [3],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Make Predictions with the Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Best Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Statistics:\n",
      "Random Forest Accuracy: 0.6757518796992481\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.35      0.43       265\n",
      "           1       0.57      0.24      0.34       228\n",
      "           2       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.68      1064\n",
      "   macro avg       0.62      0.53      0.53      1064\n",
      "weighted avg       0.64      0.68      0.63      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"XGB Classifier Statistics:\")\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Step 4: Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Step 5: Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Step 7: Make Predictions with the Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the Best Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Statistics:\n",
      "SVC Accuracy: 0.6625939849624061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51       265\n",
      "           1       0.00      0.00      0.00       228\n",
      "           2       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.66      1064\n",
      "   macro avg       0.41      0.50      0.45      1064\n",
      "weighted avg       0.51      0.66      0.57      1064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/research-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/research-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/research-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an SVC classifier\n",
    "svc_model = SVC(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svc_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "print(\"SVC Statistics:\")\n",
    "print(\"SVC Accuracy:\", svc_accuracy)\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try binary classification for promoter vs. nonpromoter\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(1, 0)\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(2, 1)\n",
    "X = df_train.drop(columns=['Sequences','Strengths'], axis=1)\n",
    "y = df_train['Strengths']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# strength_counts = df_train['Strengths'].value_counts()\n",
    "# print(\"Count of 0's:\", strength_counts.get(0, 0))  # Replace 1 with the actual value you're interested in\n",
    "# print(\"Count of 1's:\", strength_counts.get(1, 0)) \n",
    "# print(\"Count of 2's:\", strength_counts.get(2, 0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Statistics:\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "xgb_pred = xgb_classifier.predict(X_test)\n",
    "# Evaluate the accuracy\n",
    "print(\"XGB Classifier Statistics:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, xgb_pred):.2f}')\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Logistic Regression Classifier\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an SVC classifier\n",
    "svc_model = SVC()  # Use SVC instead of LogisticRegression\n",
    "svc_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "svc_pred = svc_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"SVC Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svc_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()  # Use DecisionTreeClassifier instead of SVC\n",
    "dt_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, dt_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, knn_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, knn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Naive Bayes model\n",
    "gb_model = GaussianNB()\n",
    "gb_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Gaussian Naive Bayes Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, gb_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the AdaBoost model\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "ada_pred = ada_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Adaboost Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, ada_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, ada_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the LDA model\n",
    "ld_model = LinearDiscriminantAnalysis()\n",
    "ld_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "ld_pred = ld_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Linear Discriminant Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, ld_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, ld_pred))\n",
    "\n",
    "# # Step 5: Create Confusion Matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# # Step 6: Plot Confusion Matrix using seaborn\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "#             xticklabels=['Class 0', 'Class 1'], \n",
    "#             yticklabels=['Class 0', 'Class 1'])\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
