{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the Best Classification Method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, recall_score, precision_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retreiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Shape:  (6646, 2)\n",
      "Embeddings Shape:  (6646, 1280)\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('classification_fasta_processed.csv')\n",
    "embeddings = np.load('all_embeddings_100m_mean.npy')\n",
    "print(\"Y Shape: \", y.shape)\n",
    "print(\"Embeddings Shape: \", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequences</th>\n",
       "      <th>Strengths</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1270</th>\n",
       "      <th>feature_1271</th>\n",
       "      <th>feature_1272</th>\n",
       "      <th>feature_1273</th>\n",
       "      <th>feature_1274</th>\n",
       "      <th>feature_1275</th>\n",
       "      <th>feature_1276</th>\n",
       "      <th>feature_1277</th>\n",
       "      <th>feature_1278</th>\n",
       "      <th>feature_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaagaaaataattaattttacagctgttaaaccaaacggttataac...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6646 rows Ã— 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequences  Strengths  feature_0  \\\n",
       "0     tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...          1  -0.936847   \n",
       "1     aaagaaaataattaattttacagctgttaaaccaaacggttataac...          1  -0.946999   \n",
       "2     ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...          1  -0.946999   \n",
       "3     gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...          1  -0.936847   \n",
       "4     aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...          1  -0.939334   \n",
       "...                                                 ...        ...        ...   \n",
       "6641  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6642  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6643  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6644  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "6645  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...         -1  -0.939334   \n",
       "\n",
       "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "1     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "2     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "3     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "4     -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6641  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6642  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6643  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6644  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6645  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "\n",
       "      feature_7  ...  feature_1270  feature_1271  feature_1272  feature_1273  \\\n",
       "0     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "1     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "2     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "3     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "4     -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "...         ...  ...           ...           ...           ...           ...   \n",
       "6641  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6642  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6643  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6644  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6645  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "\n",
       "      feature_1274  feature_1275  feature_1276  feature_1277  feature_1278  \\\n",
       "0        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "1        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "2        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "3        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "4        -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6641     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6642     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6643     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6644     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6645     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "\n",
       "      feature_1279  \n",
       "0        -0.153779  \n",
       "1        -0.101237  \n",
       "2        -0.101237  \n",
       "3        -0.153779  \n",
       "4        -0.107114  \n",
       "...            ...  \n",
       "6641     -0.107114  \n",
       "6642     -0.107114  \n",
       "6643     -0.107114  \n",
       "6644     -0.107114  \n",
       "6645     -0.107114  \n",
       "\n",
       "[6646 rows x 1282 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = embeddings.shape[1]\n",
    "embeddings_df = pd.DataFrame(data=embeddings, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "combined_df = pd.concat([y, embeddings_df], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5316\n",
      "Test set size: 1330\n"
     ]
    }
   ],
   "source": [
    "target_column = 'log2_foldchange'\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_shuffled = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Calculate the split indices\n",
    "train_idx, test_idx = train_test_split(df_shuffled.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the train, validation, and test DataFrames\n",
    "df_train = df_shuffled.loc[train_idx]\n",
    "df_test = df_shuffled.loc[test_idx]\n",
    "\n",
    "# Drop the index columns\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the sizes of the resulting DataFrames\n",
    "print(f\"Train set size: {len(df_train)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to CSV files\n",
    "df_train.to_csv('train_data_clf_mean.csv', index=False)\n",
    "df_test.to_csv('test_data_clf_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiClass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier model on the df_train\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(-1, 2)\n",
    "X = df_train.drop(columns=['Sequences','Strengths'], axis=1)\n",
    "y = df_train['Strengths']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: XGB Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Statistics:\n",
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.35      0.43       265\n",
      "           1       0.57      0.24      0.34       228\n",
      "           2       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.68      1064\n",
      "   macro avg       0.62      0.53      0.53      1064\n",
      "weighted avg       0.64      0.68      0.63      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"XGB Classifier Statistics:\")\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'objective': ['multi:softmax'],\n",
    "    'num_class': [3],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Make Predictions with the Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Best Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Statistics:\n",
      "Random Forest Accuracy: 0.6757518796992481\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.35      0.43       265\n",
      "           1       0.57      0.24      0.34       228\n",
      "           2       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.68      1064\n",
      "   macro avg       0.62      0.53      0.53      1064\n",
      "weighted avg       0.64      0.68      0.63      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"XGB Classifier Statistics:\")\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Step 4: Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Step 5: Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Step 7: Make Predictions with the Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the Best Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Statistics:\n",
      "SVC Accuracy: 0.6625939849624061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51       265\n",
      "           1       0.00      0.00      0.00       228\n",
      "           2       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.66      1064\n",
      "   macro avg       0.41      0.50      0.45      1064\n",
      "weighted avg       0.51      0.66      0.57      1064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/research-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/research-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/research-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an SVC classifier\n",
    "svc_model = SVC(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svc_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "print(\"SVC Statistics:\")\n",
    "print(\"SVC Accuracy:\", svc_accuracy)\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try binary classification for promoter vs. nonpromoter\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(1, 0)\n",
    "df_train['Strengths'] = df_train['Strengths'].replace(2, 1)\n",
    "X = df_train.drop(columns=['Sequences','Strengths'], axis=1)\n",
    "y = df_train['Strengths']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# strength_counts = df_train['Strengths'].value_counts()\n",
    "# print(\"Count of 0's:\", strength_counts.get(0, 0))  # Replace 1 with the actual value you're interested in\n",
    "# print(\"Count of 1's:\", strength_counts.get(1, 0)) \n",
    "# print(\"Count of 2's:\", strength_counts.get(2, 0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Statistics:\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "xgb_pred = xgb_classifier.predict(X_test)\n",
    "# Evaluate the accuracy\n",
    "print(\"XGB Classifier Statistics:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, xgb_pred):.2f}')\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Logistic Regression Classifier\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an SVC classifier\n",
    "svc_model = SVC()  # Use SVC instead of LogisticRegression\n",
    "svc_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "svc_pred = svc_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"SVC Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svc_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()  # Use DecisionTreeClassifier instead of SVC\n",
    "dt_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, dt_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, knn_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, knn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Naive Bayes model\n",
    "gb_model = GaussianNB()\n",
    "gb_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Gaussian Naive Bayes Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, gb_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the AdaBoost model\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "ada_pred = ada_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Adaboost Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, ada_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, ada_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Statistics:\n",
      "Accuracy: 0.7819548872180451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69       493\n",
      "           1       0.71      1.00      0.83       571\n",
      "\n",
      "    accuracy                           0.78      1064\n",
      "   macro avg       0.86      0.76      0.76      1064\n",
      "weighted avg       0.84      0.78      0.77      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the LDA model\n",
    "ld_model = LinearDiscriminantAnalysis()\n",
    "ld_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "ld_pred = ld_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Linear Discriminant Statistics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, ld_pred)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, ld_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequences</th>\n",
       "      <th>Strengths</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1270</th>\n",
       "      <th>feature_1271</th>\n",
       "      <th>feature_1272</th>\n",
       "      <th>feature_1273</th>\n",
       "      <th>feature_1274</th>\n",
       "      <th>feature_1275</th>\n",
       "      <th>feature_1276</th>\n",
       "      <th>feature_1277</th>\n",
       "      <th>feature_1278</th>\n",
       "      <th>feature_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaagaaaataattaattttacagctgttaaaccaaacggttataac...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.946999</td>\n",
       "      <td>-0.824914</td>\n",
       "      <td>-0.470066</td>\n",
       "      <td>-0.244439</td>\n",
       "      <td>-0.711039</td>\n",
       "      <td>-0.126911</td>\n",
       "      <td>0.556981</td>\n",
       "      <td>-0.249472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>-0.519048</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>-0.911779</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>-0.101237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.936847</td>\n",
       "      <td>-0.781433</td>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.618907</td>\n",
       "      <td>-0.142214</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>-0.227962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>-0.431873</td>\n",
       "      <td>-0.034174</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>-0.867468</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.084448</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.153779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>-0.752792</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.644720</td>\n",
       "      <td>-0.147364</td>\n",
       "      <td>0.547578</td>\n",
       "      <td>-0.244620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592513</td>\n",
       "      <td>-0.447916</td>\n",
       "      <td>-0.154701</td>\n",
       "      <td>0.645616</td>\n",
       "      <td>-0.978199</td>\n",
       "      <td>-0.352725</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>-0.076592</td>\n",
       "      <td>-0.107114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6646 rows Ã— 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequences  Strengths  feature_0  \\\n",
       "0     tagatgtccttgattaacaccaaaattaaaccttttaaaaaccagg...          2  -0.936847   \n",
       "1     aaagaaaataattaattttacagctgttaaaccaaacggttataac...          2  -0.946999   \n",
       "2     ctgctgttccttgcgatcgaaaagatcaagggcggaccggtatccg...          2  -0.946999   \n",
       "3     gcggaagcacaaattgcaccaggtacggaactaaaagccgtagatg...          2  -0.936847   \n",
       "4     aaatacttatggtgcgctggcttctttggaacttgcgcagcaattt...          2  -0.939334   \n",
       "...                                                 ...        ...        ...   \n",
       "6641  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...          0  -0.939334   \n",
       "6642  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...          0  -0.939334   \n",
       "6643  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...          0  -0.939334   \n",
       "6644  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...          0  -0.939334   \n",
       "6645  gatactagatgtagttgaaaaaagattcaaccacacaatatatagc...          0  -0.939334   \n",
       "\n",
       "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "1     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "2     -0.824914  -0.470066  -0.244439  -0.711039  -0.126911   0.556981   \n",
       "3     -0.781433  -0.525665  -0.327091  -0.618907  -0.142214   0.555200   \n",
       "4     -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6641  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6642  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6643  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6644  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "6645  -0.752792  -0.355315  -0.209782  -0.644720  -0.147364   0.547578   \n",
       "\n",
       "      feature_7  ...  feature_1270  feature_1271  feature_1272  feature_1273  \\\n",
       "0     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "1     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "2     -0.249472  ...      0.678970     -0.519048     -0.002377      0.652751   \n",
       "3     -0.227962  ...      0.693298     -0.431873     -0.034174      0.701798   \n",
       "4     -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "...         ...  ...           ...           ...           ...           ...   \n",
       "6641  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6642  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6643  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6644  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "6645  -0.244620  ...      0.592513     -0.447916     -0.154701      0.645616   \n",
       "\n",
       "      feature_1274  feature_1275  feature_1276  feature_1277  feature_1278  \\\n",
       "0        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "1        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "2        -0.911779     -0.233074      0.052144      0.210270     -0.042073   \n",
       "3        -0.867468     -0.268788     -0.084448      0.357413     -0.061708   \n",
       "4        -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6641     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6642     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6643     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6644     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "6645     -0.978199     -0.352725      0.029607      0.186247     -0.076592   \n",
       "\n",
       "      feature_1279  \n",
       "0        -0.153779  \n",
       "1        -0.101237  \n",
       "2        -0.101237  \n",
       "3        -0.153779  \n",
       "4        -0.107114  \n",
       "...            ...  \n",
       "6641     -0.107114  \n",
       "6642     -0.107114  \n",
       "6643     -0.107114  \n",
       "6644     -0.107114  \n",
       "6645     -0.107114  \n",
       "\n",
       "[6646 rows x 1282 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('classification_fasta_processed.csv')\n",
    "data['Strengths'] = data['Strengths'].replace(1,2)\n",
    "data['Strengths'] = data['Strengths'].replace(0,1)\n",
    "data['Strengths'] = data['Strengths'].replace(-1,0)\n",
    "\n",
    "embeddings = np.load('all_embeddings_100m_mean.npy')\n",
    "num_features = embeddings.shape[1]\n",
    "embeddings_df = pd.DataFrame(data=embeddings, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "combined_df = pd.concat([data, embeddings_df], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = combined_df[combined_df['Strengths'] == 0]\n",
    "class_0_downsampled = resample(class_0, replace=False, n_samples=1473, random_state=42)\n",
    "class_2 = combined_df[combined_df['Strengths']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([class_0_downsampled,class_2])\n",
    "total_df['binary_label'] = total_df['Strengths'].apply(lambda x: 1 if x == 2 else 0)\n",
    "X = total_df.drop(['Strengths', 'binary_label', 'Sequences'], axis=1)\n",
    "y = total_df['binary_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Metrics:\n",
      "Accuracy: 0.8144796380090498\n",
      "F1 Score: 0.7696629213483146\n",
      "Recall: 0.6255707762557078\n",
      "Precision: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       446\n",
      "           1       1.00      0.63      0.77       438\n",
      "\n",
      "    accuracy                           0.81       884\n",
      "   macro avg       0.87      0.81      0.81       884\n",
      "weighted avg       0.86      0.81      0.81       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_f1 = f1_score(y_test, rf_predictions)\n",
    "rf_recall = recall_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forest Classifier Metrics:\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"F1 Score:\", rf_f1)\n",
    "print(\"Recall:\", rf_recall)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Metrics:\n",
      "Accuracy: 0.8144796380090498\n",
      "F1 Score: 0.7696629213483146\n",
      "Recall: 0.6255707762557078\n",
      "Precision: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       446\n",
      "           1       1.00      0.63      0.77       438\n",
      "\n",
      "    accuracy                           0.81       884\n",
      "   macro avg       0.87      0.81      0.81       884\n",
      "weighted avg       0.86      0.81      0.81       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"XGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Metrics:\n",
      "Accuracy: 0.8144796380090498\n",
      "F1 Score: 0.7696629213483146\n",
      "Recall: 0.6255707762557078\n",
      "Precision: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       446\n",
      "           1       1.00      0.63      0.77       438\n",
      "\n",
      "    accuracy                           0.81       884\n",
      "   macro avg       0.87      0.81      0.81       884\n",
      "weighted avg       0.86      0.81      0.81       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Support Vector Classifier\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svc_predictions = svc_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "svc_accuracy = accuracy_score(y_test, svc_predictions)\n",
    "svc_f1 = f1_score(y_test, svc_predictions)\n",
    "svc_recall = recall_score(y_test, svc_predictions)\n",
    "svc_precision = precision_score(y_test, svc_predictions)\n",
    "\n",
    "print(\"Support Vector Classifier Metrics:\")\n",
    "print(\"Accuracy:\", svc_accuracy)\n",
    "print(\"F1 Score:\", svc_f1)\n",
    "print(\"Recall:\", svc_recall)\n",
    "print(\"Precision:\", svc_precision)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, svc_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "Accuracy: 0.8144796380090498\n",
      "F1 Score: 0.7696629213483146\n",
      "Recall: 0.6255707762557078\n",
      "Precision: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       446\n",
      "           1       1.00      0.63      0.77       438\n",
      "\n",
      "    accuracy                           0.81       884\n",
      "   macro avg       0.87      0.81      0.81       884\n",
      "weighted avg       0.86      0.81      0.81       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "lr_predictions = lr_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_f1 = f1_score(y_test, lr_predictions)\n",
    "lr_recall = recall_score(y_test, lr_predictions)\n",
    "lr_precision = precision_score(y_test, lr_predictions)\n",
    "\n",
    "print(\"Linear Regression Metrics:\")\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "print(\"F1 Score:\", lr_f1)\n",
    "print(\"Recall:\", lr_recall)\n",
    "print(\"Precision:\", lr_precision)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "            xticklabels=['Class 0', 'Class 1'], \n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
